{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! unzip aia-st2-forex-predict-overview.zip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "pip install --upgrade pip\n",
    "#pip install --upgrade tensorflow_gpu # version 2.0.0\n",
    "pip install tensorflow-gpu==2.0.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! mkdir model submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74278, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training_set.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170 05:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12053</td>\n",
       "      <td>1.12079</td>\n",
       "      <td>1.12050</td>\n",
       "      <td>1.12067</td>\n",
       "      <td>302.690002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170 05:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12066</td>\n",
       "      <td>1.12074</td>\n",
       "      <td>1.12051</td>\n",
       "      <td>1.12070</td>\n",
       "      <td>486.690001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170 05:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12070</td>\n",
       "      <td>1.12071</td>\n",
       "      <td>1.12065</td>\n",
       "      <td>1.12070</td>\n",
       "      <td>212.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170 05:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12070</td>\n",
       "      <td>1.12072</td>\n",
       "      <td>1.12050</td>\n",
       "      <td>1.12061</td>\n",
       "      <td>811.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170 05:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12060</td>\n",
       "      <td>1.12079</td>\n",
       "      <td>1.12027</td>\n",
       "      <td>1.12029</td>\n",
       "      <td>502.870001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time  Weekday     Open     High      Low    Close      Volume\n",
       "0  170 05:00:00        0  1.12053  1.12079  1.12050  1.12067  302.690002\n",
       "1  170 05:10:00        0  1.12066  1.12074  1.12051  1.12070  486.690001\n",
       "2  170 05:20:00        0  1.12070  1.12071  1.12065  1.12070  212.120000\n",
       "3  170 05:30:00        0  1.12070  1.12072  1.12050  1.12061  811.989999\n",
       "4  170 05:40:00        0  1.12060  1.12079  1.12027  1.12029  502.870001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "del df['Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['Close']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "data = ss.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74278, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 30 #hyperparam\n",
    "n_output_timestamp = 30 #hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74218, 30, 1), (74218, 30, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "for i in range(len(data)-window-n_output_timestamp):\n",
    "    X.append( data[i:i+window, :] )\n",
    "    Y.append( data[i+window:i+window+n_output_timestamp, :] )\n",
    "X = np.array(X)    \n",
    "Y = np.array(Y)  \n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 30, 1) (1024, 30, 1)\n",
      "(1024, 30, 1) (1024, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y)).shuffle(1024).batch(1024)\n",
    "\n",
    "for x, y in dataset:\n",
    "    print(x.numpy().shape, y.numpy().shape)\n",
    "    break\n",
    "    \n",
    "x, y = next(iter(dataset))\n",
    "print(x.numpy().shape, y.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, n_input_feature: int, enc_units: int) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.rnn = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        \"\"\"\n",
    "        batch_size=B, n_input_timestamp=T_in\n",
    "        n_input_feature=F_in, enc_units=H_enc\n",
    "        input:\n",
    "            x.shape : (B, T_in, F_in)\n",
    "        return:\n",
    "            output.shape : (B, T_in, H_enc)\n",
    "            state.shape : (B, H_enc)\n",
    "        \"\"\"\n",
    "        output, state = self.rnn(x)\n",
    "        return output, state\n",
    "    \n",
    "# try\n",
    "#e = Encoder(6,100)\n",
    "#enc_output, enc_hidden =  e(x)\n",
    "#x.shape, enc_output.shape, enc_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units: int) -> None:\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query: tf.Tensor, values: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        \"\"\"\n",
    "        batch_size=B, n_input_timestamp=T_in\n",
    "        enc_units=H_enc, dec_units=H_dec, units=U\n",
    "        input:\n",
    "            query.shape : (B, H_dec)\n",
    "            values.shape : (B, T_in, H_enc)\n",
    "        return:\n",
    "            context_vector.shape : (B, H_enc)\n",
    "            attention_weights: (B, T_in, 1)\n",
    "        \"\"\"\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "# try    \n",
    "#att = BahdanauAttention(70)\n",
    "#dec_hidden = enc_hidden[:, :90] #init\n",
    "#context_vector, attention_weights = att(dec_hidden, enc_output)\n",
    "#enc_hidden.shape, dec_hidden.shape, enc_output.shape, context_vector.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, n_output_feature: int, dec_units: int) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.rnn = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(n_output_feature)\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x: tf.Tensor, hidden: tf.Tensor, enc_output: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "        \"\"\"\n",
    "        batch_size=B, n_output_timestamp=T_out:=1, n_input_timestamp=T_in\n",
    "        n_output_feature=F_out, \n",
    "        enc_units=H_enc, dec_units=units=H_dec, \n",
    "        input:\n",
    "            x.shape : (B, T_out=1, F_out)\n",
    "            hidden.shape : (B, H_dec)\n",
    "            enc_output.shape : (B, T_in, H_enc)\n",
    "        return:\n",
    "            x.shape : (B, T_out=1, F_out)\n",
    "            state.shape : (B, H_dec)\n",
    "            attention_weights.shape : (B, T_in, 1)\n",
    "        \"\"\"\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)# (B, 1, H + F_out)\n",
    "        output, state = self.rnn(x) # (B, T_out=1, H), (B, H)\n",
    "        #output = tf.reshape(output, (-1, output.shape[2])) # (B, H)\n",
    "        x = self.fc(output)# (B, T_out=1, F_out)\n",
    "        return x, state, attention_weights\n",
    "# try    \n",
    "#d = Decoder(1,80)\n",
    "#dec_input = y[:,0:1,:]\n",
    "#predictions, dec_hidden, _ = d(dec_input, dec_hidden, enc_output)\n",
    "#predictions.shape, dec_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 n_input_timestamp: int, \n",
    "                 n_input_feature: int, \n",
    "                 enc_units: int,\n",
    "                 n_output_timestamp: int, \n",
    "                 n_output_feature: int, \n",
    "                 dec_units: int) -> None:\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        assert(n_input_feature==n_output_feature)\n",
    "        self.n_input_timestamp = n_input_timestamp\n",
    "        self.n_output_timestamp = n_output_timestamp\n",
    "        self.n_input_feature = n_input_feature\n",
    "        self.n_output_feature = n_output_feature\n",
    "        #self.fc_enc2dec = tf.keras.layers.Dense(n_output_feature) # enc2dec_hidden\n",
    "        self.enc = Encoder(n_input_feature, enc_units)\n",
    "        self.dec = Decoder(n_output_feature, dec_units)\n",
    "        \n",
    "    def call(self, source, target=None, test_mode=False):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            source.shape : (B, T_in, F_in)\n",
    "            target.shape : (B, T_out, F_out)\n",
    "        return:\n",
    "            pred_target : (B, T_out, F_out)\n",
    "        \"\"\"\n",
    "        enc_output, enc_hidden =  self.enc(source)\n",
    "        #dec_hidden = self.self.fc_enc2dec(enc_hidden) \n",
    "        dec_hidden = enc_hidden #init\n",
    "        dec_input = source[:,-1:,:] #init\n",
    "        pred_target = []\n",
    "        if test_mode or (target is None) :   \n",
    "            for t in range(self.n_output_timestamp):\n",
    "                predictions, dec_hidden, _ = self.dec(dec_input, dec_hidden, enc_output)\n",
    "                dec_input = predictions\n",
    "                pred_target += [predictions]\n",
    "        else:\n",
    "            for t in range(self.n_output_timestamp):\n",
    "                predictions, dec_hidden, _ = self.dec(dec_input, dec_hidden, enc_output)\n",
    "                dec_input = target[:,t:t+1,:] #(B,1,F)  # using teacher forcing\n",
    "                pred_target += [predictions]\n",
    "   \n",
    "        return tf.concat(pred_target, 1)        \n",
    "# try                \n",
    "#s2s = Seq2Seq(200,6,100,30,6,100)    \n",
    "#tgt = s2s(x,y, test_mode=0)\n",
    "#tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model:tf.keras.Model, src: tf.Tensor, tgt: tf.Tensor):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        tgt_ = model(src, tgt, test_mode=0)\n",
    "        loss = tf.reduce_mean(tf.abs(tgt-tgt_))\n",
    "        \n",
    "    variables = model.trainable_variables \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(window,X.shape[-1],100,n_output_timestamp,Y.shape[-1],100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try run (without backward)\n",
    "for x, y in dataset:\n",
    "    tgt = model(x,y, test_mode=0)\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# try run\n",
    "for x, y in dataset:\n",
    "    loss = train_step(optimizer,model, x, y)\n",
    "    print(loss.numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=1):\n",
    "    for epoch in range(epochs):\n",
    "        loss_ = []\n",
    "        for bn, (x, y) in enumerate(dataset):\n",
    "            loss = train_step(model, x, y)\n",
    "            loss_.append(loss.numpy())\n",
    "            if bn%5 ==0 : print(f\"[{epoch}][{bn}]\", loss.numpy())\n",
    "        print(f\"[{epoch}]\", np.mean(loss_))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "optimizer=tf.keras.optimizers.Adam(3e-2)\n",
    "train(model, epochs=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.load_weights('model/model_seq2seq_epo4_0.00198.h5') #0.0020"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "optimizer=tf.keras.optimizers.Adam(3e-3)\n",
    "train(model, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model/model_seq2seq_epo8_0.00128.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test & Save Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74218 (1, 30, 1)\n",
      "74218 (30,)\n"
     ]
    }
   ],
   "source": [
    "# pred test\n",
    "n_pred_timestamp = 30\n",
    "data_ = np.array(list(data.flatten()) + [np.nan]*n_pred_timestamp)\n",
    "for i in range(len(data)-window-n_output_timestamp, \n",
    "               len(data)-window-n_output_timestamp+n_pred_timestamp):\n",
    "    X_test = data_[None, i:i+window, None]\n",
    "    assert(np.isnan(X_test).sum()==0 )\n",
    "    print(i, X_test.shape)\n",
    "    y_test = model(X_test)\n",
    "    print(i, y_test[0,:,0].shape)\n",
    "    data_[-30:] = y_test[0,:,0]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = data_[-30:].reshape((-1,1))\n",
    "pred_ = ss.inverse_transform(pred)\n",
    "pred_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_df = pd.read_csv('sample_submission.csv')\n",
    "op_df['Close'] = pred_\n",
    "op_df.to_csv('submit/my_submission_seq2seq.csv', index=False) # mse: 0.0007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from acc import score\n",
    "score(pred_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tf-2.0.0)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
